{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitanaconda3virtualenv0eb00d040fcb4c57aee1eea72382a570",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import * #flatten, text_processing, prepare_dataset\n",
    "from collections import Counter\n",
    "import tensorflow as tf \n",
    "import os"
   ]
  },
  {
   "source": [
    "## Data Engineering and Processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(pd.read_csv('severeinjury.csv', encoding = 'latin9')['text'])\n",
    "text = text_processing(data)\n",
    "\n",
    "characters = set(list(Counter(flatten(text)).keys()))\n",
    "n_char = len(characters)\n",
    "\n",
    "char2idx = dict(zip(characters, range(4, n_char + 4)))\n",
    "\n",
    "noisy_text = get_noisy_text(text[:100], char2idx)\n",
    "\n",
    "paddded_source_text_indexes, paddded_target_text_indexes, source_length, target_length = prepare_dataset(char2idx, text[:100], noisy_text)\n",
    "\n",
    "ds_source = tf.data.Dataset.from_tensor_slices(paddded_source_text_indexes)\n",
    "ds_target = tf.data.Dataset.from_tensor_slices(paddded_target_text_indexes)\n",
    "ds_source_length = tf.data.Dataset.from_tensor_slices(source_length)\n",
    "ds_target_length = tf.data.Dataset.from_tensor_slices(target_length)\n",
    "dataset = tf.data.Dataset.zip((ds_source, ds_target, ds_source_length, ds_target_length))"
   ]
  },
  {
   "source": [
    "## Model Definition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<ZipDataset shapes: ((173,), (173,), (), ()), types: (tf.int32, tf.int32, tf.int32, tf.int32)>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "vector_size = 128\n",
    "enc_units = 256\n",
    "dec_units = 2 * enc_units\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "encoder = Encoder(100, vector_size, enc_units)\n",
    "decoder = Decoder(100, vector_size, dec_units)\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n"
   ]
  }
 ]
}